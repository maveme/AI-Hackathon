{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <h1><center> **Hackathon AI - VU Amsterdam** </center></h1>\n",
    "<h2><center>FACE RECOGNITION WITH OPEN CV IN PYTHON</center></h2>\n",
    "\n",
    "<center>This is a tutorial for one of the most famous projects for beginners in computer vision. Here, we are going to build a module for face recognition step by step. First, we have to install some libraries that will allow us to develop a project that involves both deep learning and OpenCV.</center>\n",
    "\n",
    "\n",
    "\n",
    "**INSTALL OPENCV:**\n",
    "\n",
    "1) If you have previous/other manually installed (= not installed via pip) version of OpenCV installed (e.g. cv2 module in the root of Python's site-packages), remove it before installation to avoid conflicts.\n",
    "\n",
    "2) Make sure that your pip version is up-to-date (19.3 is the minimum supported version): pip install --upgrade pip. Check version with pip -V. For example Linux distributions ship usually with very old pip versions which cause a lot of unexpected problems especially with the manylinux format.\n",
    "\n",
    "3) Select the correct package for your environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start coding. To train the machine to recognize faces, OpenCV provides a training method or pretrained models, that can be read using the cv2.CascadeClassifier method. Here, we import a Cascade for frontal faces, that is, a file that allows our program to train in recognizing frontal faces. In other words, our faceCascade is an object detection algorithm used to identify faces in an image or a real time video.\n",
    "\n",
    "When you install OpenCV, you get access to XML files with the Haar features for:\n",
    "- eyes\n",
    "- frontal face\n",
    "- full body\n",
    "- upper body\n",
    "- lower body\n",
    "- cats\n",
    "- stop signs\n",
    "- license plates, etc. \n",
    "\n",
    "You can find this file in the official repository <a href=\"https://github.com/opencv/opencv/tree/master/data/haarcascades\">official repository</a>. You can experiment downloading more xml files, the ones that best suit your project, and see what happens. Just instert the  file path in the cv2.CascadeClassifier() function. Remember to change the variables' name so that it refers to the object your program will actually detect! Last, but not least, you can work with multiple cascades in the same program. Just create different variables, each storing a different cv2.CascadeClassifier(cascPath). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cascPath = \"haarcascade_frontalface_default.xml\"\n",
    "faceCascade = cv2.CascadeClassifier(cascPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we set video source to the default webcam (at index 0). You can also provide a file name here , the program will read in video file BUT you have to install ffmpeg (not easy :( !). In particular, we use:\n",
    "- VideoCapture() method: to open video file or image file sequence or a capturing device or a IP video stream for video capturing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_capture = cv2.VideoCapture(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The crucial part of the code is actually making the program able to detect faces. We first capture the video through the method read() that reads video frames from a video source (a webcam, in our case) frame by frame. \n",
    "To detect faces in image we use detectMultiScale, a general function for object detection which in this case detects faces as we are calling it on the face cascade. We previously convert our frame image to grey scale so that manipulations are allowed, and that is going to be our function's first parameter. Then, we have:\n",
    "- scale factor = to compensate faces' different distances from camera\n",
    "- minNeighbors = how many objects are detected near the current one (before it declares the face found)\n",
    "- minSize = size of each window \n",
    "\n",
    "Then we draw rectangle around detected faces, where:\n",
    "-  x, y = location of rectangle\n",
    "-  w, h = rectangle width and height\n",
    "\n",
    "Finally, we display the resulting video frame with cv2.imshow() function. \n",
    "To close the program, we wait for the user to click on the window and press Esc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    ret, frame = video_capture.read()\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    faces = faceCascade.detectMultiScale(\n",
    "        gray,\n",
    "        scaleFactor = 1.1,\n",
    "        minNeighbors = 5,\n",
    "        minSize = (30, 30)\n",
    "    )\n",
    "\n",
    "    # draw rectangle around afces\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(frame, (x,y), (x+w, y+h), (0, 255, 0), 2)\n",
    "\n",
    "    # display resulting frame\n",
    "    cv2.imshow('VIDEO', frame)\n",
    "    \n",
    "    k = cv2.waitKey(1)\n",
    "    if k == 27:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- release() method: this releases the webcam and closes imshow() windows\n",
    "- destroyAllWindows() method: allows users to destroy or close all windows at any time after exiting the script. If you have multiple windows open at the same time and you want to close then you would use this function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to detect objects from pictures and not videos, write the code in this way. The principles are the same, for whatever cascade you will decide to use. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "imagePath = \"abba.png\"\n",
    "cascPath = \"haarcascade_frontalface_default.xml\"\n",
    "\n",
    "faceCascade = cv2.CascadeClassifier(cascPath)\n",
    "\n",
    "# read image\n",
    "image = cv2.imread(imagePath)\n",
    "# convert imgae in grayscale to perform operations\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "faces = faceCascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=10, minSize=(30,30)) #flags=cv2.cv.CV_HAAR_SCALE_IMAGE\n",
    "\n",
    "# expected output function = list of rectangles in which it believes it found a face\n",
    "print (\"found {0} faces!\".format(len(faces)))\n",
    "\n",
    "# Draw rectangle around detected faces\n",
    "# x, y = location of rectangle\n",
    "# w, h = rectangle width and height\n",
    "for (x, y, w, h) in faces:\n",
    "    cv2.rectangle(image, (x,y), (x+w, y+h), (0, 255, 0), 2)\n",
    "\n",
    "# display image\n",
    "# wait for user to press a key\n",
    "cv2.imshow(\"Faces found\", image)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<center>Thank you for following this tutorial and good luck with your project! :)</center>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "&copy; 2022 - **VU Amsterdam**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
